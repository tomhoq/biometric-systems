{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69588429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoModelForImageClassification, ViTImageProcessor, Trainer\n",
    "from transformers import ViTForImageClassification\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from sklearn.metrics import accuracy_score, classification_report, det_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import math\n",
    "import operator\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from src.DET import DET\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import fixed, interact\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import describe, gaussian_kde\n",
    "import random\n",
    "from PIL import Image\n",
    "#from src.auxiliary_utils import Auxiliary\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf5656da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972    05594d126.tiff\n",
      "973    05594d159.tiff\n",
      "974      05594d3.tiff\n",
      "975     05594d33.tiff\n",
      "976    05594d350.tiff\n",
      "977    05594d355.tiff\n",
      "978    05594d385.tiff\n",
      "979    05594d416.tiff\n",
      "980     05594d63.tiff\n",
      "981     05594d96.tiff\n",
      "982    05596d148.tiff\n",
      "983     05596d28.tiff\n",
      "984    05596d324.tiff\n",
      "Name: filename, dtype: object\n",
      "972    05594d158.tiff\n",
      "973    05594d349.tiff\n",
      "974    05594d356.tiff\n",
      "975    05594d386.tiff\n",
      "976      05594d4.tiff\n",
      "977    05594d415.tiff\n",
      "978     05594d62.tiff\n",
      "979     05594d95.tiff\n",
      "980    05596d147.tiff\n",
      "981     05596d27.tiff\n",
      "982    05596d323.tiff\n",
      "983     05596d57.tiff\n",
      "984    05597d249.tiff\n",
      "Name: filename, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05485d154.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05647d3.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05512d102.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05484d132.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05248d493.tiff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>05663d307.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>05728d85.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>05306d479.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>05305d393.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>05406d471.tiff</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1499 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  gender\n",
       "0     05485d154.tiff       1\n",
       "1       05647d3.tiff       1\n",
       "2     05512d102.tiff       1\n",
       "3     05484d132.tiff       1\n",
       "4     05248d493.tiff       1\n",
       "...              ...     ...\n",
       "1495  05663d307.tiff       0\n",
       "1496   05728d85.tiff       0\n",
       "1497  05306d479.tiff       0\n",
       "1498  05305d393.tiff       0\n",
       "1499  05406d471.tiff       0\n",
       "\n",
       "[1499 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_path= \"./GFI_database_with_labels/info/\"\n",
    "right_eye_path = \"./GFI_database_with_labels/Right_eye/\"\n",
    "left_eye_path = \"./GFI_database_with_labels/Left_eye/\"\n",
    "\n",
    "right_eye = np.loadtxt(f'{info_path}List_Right_eye.txt', dtype=str)\n",
    "right_eye = pd.DataFrame(right_eye, columns=['filename', 'gender'])\n",
    "right_eye['gender'] = pd.to_numeric(right_eye['gender'])\n",
    "left_eye = np.loadtxt(f'{info_path}List_Left_eye.txt', dtype=str)\n",
    "left_eye = pd.DataFrame(left_eye, columns=['filename','gender'])\n",
    "#remove unexistent pair\n",
    "left_eye = left_eye.drop(left_eye.index[left_eye[\"filename\"] == \"04233d1786.tiff\"].tolist()[0])\n",
    "right_eye = right_eye.drop(right_eye.index[right_eye[\"filename\"] == \"04418d870.tiff\"].tolist()[0])\n",
    "\n",
    "left_eye['gender'] = pd.to_numeric(left_eye['gender'])\n",
    "sorted_right_eye = right_eye.sort_values(by=['filename']).reset_index(drop=True)\n",
    "sorted_left_eye = left_eye.sort_values(by=['filename']) .reset_index(drop=True)\n",
    "\n",
    "print(sorted_right_eye['filename'][972:985])\n",
    "print(sorted_left_eye['filename'][972:985])\n",
    "\n",
    "right_eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "909970a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1499it [00:03, 496.75it/s]\n"
     ]
    }
   ],
   "source": [
    "both_eyes = pd.DataFrame(columns=[\"right_eye_filename\", \"left_eye_filename\", \"gender\"])\n",
    "j = 0\n",
    "num_found = 0\n",
    "for i, file_r in tqdm(enumerate(sorted_right_eye[\"filename\"])):\n",
    "    # Parse subject ID and number from right eye filename\n",
    "    base_r = file_r.split(\".\")[0]\n",
    "    subject_r = base_r.split(\"d\")[0]\n",
    "    num_r = int(base_r.split(\"d\")[-1])\n",
    "    # Search for matching left eye candidates\n",
    "    for file_l in sorted_left_eye[\"filename\"]:\n",
    "        base_l = file_l.split(\".\")[0]\n",
    "        subject_l = base_l.split(\"d\")[0]\n",
    "        num_l = int(base_l.split(\"d\")[-1])\n",
    "\n",
    "        if subject_r == subject_l and abs(num_r - num_l) == 1:\n",
    "            gender_r = right_eye[right_eye[\"filename\"] == file_r][\"gender\"].values[0]\n",
    "            gender_l = left_eye[left_eye[\"filename\"] == file_l][\"gender\"].values[0]\n",
    "\n",
    "            if gender_r == gender_l:\n",
    "                both_eyes.loc[j] = [file_r, file_l, gender_r]\n",
    "                j += 1\n",
    "                num_found += 1\n",
    "                break  # once matched, stop searching left_eye for this right_eye\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f727248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "1    747\n",
       "0    733\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_eyes[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1cfbff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right_eye_filename</th>\n",
       "      <th>left_eye_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02463d1892.tiff</td>\n",
       "      <td>02463d1893.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02463d1910.tiff</td>\n",
       "      <td>02463d1911.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02463d1928.tiff</td>\n",
       "      <td>02463d1929.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02463d1947.tiff</td>\n",
       "      <td>02463d1946.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02463d1965.tiff</td>\n",
       "      <td>02463d1964.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>05964d23.tiff</td>\n",
       "      <td>05964d24.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>05965d13.tiff</td>\n",
       "      <td>05965d14.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>05966d22.tiff</td>\n",
       "      <td>05966d23.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>05967d13.tiff</td>\n",
       "      <td>05967d14.tiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>05968d13.tiff</td>\n",
       "      <td>05968d14.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     right_eye_filename left_eye_filename\n",
       "0       02463d1892.tiff   02463d1893.tiff\n",
       "1       02463d1910.tiff   02463d1911.tiff\n",
       "2       02463d1928.tiff   02463d1929.tiff\n",
       "3       02463d1947.tiff   02463d1946.tiff\n",
       "4       02463d1965.tiff   02463d1964.tiff\n",
       "...                 ...               ...\n",
       "1475      05964d23.tiff     05964d24.tiff\n",
       "1476      05965d13.tiff     05965d14.tiff\n",
       "1477      05966d22.tiff     05966d23.tiff\n",
       "1478      05967d13.tiff     05967d14.tiff\n",
       "1479      05968d13.tiff     05968d14.tiff\n",
       "\n",
       "[1480 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "both_eyes[[\"right_eye_filename\", \"left_eye_filename\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fc8efe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1184, 2)\n",
      "X_test shape: (296, 2)\n",
      "y_train shape: (1184,)\n",
      "y_test shape: (296,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#total_x =np.concatenate([right_eye_X, left_eye_X])\n",
    "#total_y = np.concatenate([right_eye_y, left_eye_y])\n",
    "\n",
    "# Determine the number of samples for each split\n",
    "X_train, X_test, y_train, y_test = train_test_split(both_eyes[[\"right_eye_filename\", \"left_eye_filename\"]], both_eyes[\"gender\"], test_size=0.20, random_state=42)  \n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e53f1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1184it [05:15,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for row, label in tqdm(zip(X_train.itertuples(index=False), y_train)):\n",
    "    r_file = row.right_eye_filename\n",
    "    l_file = row.left_eye_filename\n",
    "\n",
    "    r_image = Image.open(f\"{right_eye_path}/{r_file}\")\n",
    "    l_image = Image.open(f\"{left_eye_path}/{l_file}\")\n",
    "    w= r_image.width + l_image.width\n",
    "    h = r_image.height\n",
    "    combined_image = Image.new(\"RGB\", (w, h))\n",
    "\n",
    "    combined_image.paste(r_image, (0, 0))\n",
    "    combined_image.paste(l_image, (r_image.width, 0))\n",
    "    if label == 0:\n",
    "        combined_image.save(f\"./both_eyes_together/train/male/{r_file}\")\n",
    "    else:\n",
    "        combined_image.save(f\"./both_eyes_together/train/female/{r_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "affa6f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [00:27, 10.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for row, label in tqdm(zip(X_test.itertuples(index=False), y_test)):\n",
    "    r_file = row.right_eye_filename\n",
    "    l_file = row.left_eye_filename\n",
    "\n",
    "    r_image = Image.open(f\"{right_eye_path}/{r_file}\")\n",
    "    l_image = Image.open(f\"{left_eye_path}/{l_file}\")\n",
    "    w= r_image.width + l_image.width\n",
    "    h = r_image.height\n",
    "    combined_image = Image.new(\"RGB\", (w, h))\n",
    "\n",
    "    combined_image.paste(r_image, (0, 0))\n",
    "    combined_image.paste(l_image, (r_image.width, 0))\n",
    "    if label == 0:\n",
    "        combined_image.save(f\"./both_eyes_together/test/male/{r_file}\")\n",
    "    else:\n",
    "        combined_image.save(f\"./both_eyes_together/test/female/{r_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5e1b27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././both_eyes_together/train: 0 files\n",
      "././both_eyes_together/train\\female: 582 files\n",
      "././both_eyes_together/train\\male: 602 files\n",
      "Total files: 1184\n",
      "././both_eyes_together/test: 0 files\n",
      "././both_eyes_together/test\\female: 0 files\n",
      "././both_eyes_together/test\\male: 0 files\n",
      "Total files: 0\n"
     ]
    }
   ],
   "source": [
    "path = \"./both_eyes_together\"\n",
    "\n",
    "def count_files_in_dirs(root_dir):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        num_files = len([f for f in filenames if not f.startswith('.')])  # skip hidden files\n",
    "        print(f\"{dirpath}: {num_files} files\")\n",
    "    print(\"Total files:\", sum(len(files) for _, _, files in os.walk(root_dir)))\n",
    "\n",
    "count_files_in_dirs(f'./{path}/train')\n",
    "count_files_in_dirs(f'./{path}/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3cf0328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a31d5455b24fd2800c49b25a0c0f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1184 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d4977ee00643aaaaa17d72ef784539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/296 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545b28ccbfa44acaae4a599e6ba15267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/1184 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb6f00091b64093a76e8ea5ed35c5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/296 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4434972a534d92b094c1ff88c3735c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deff29a471074c0d985e89eff2416bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 1184\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 296\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "path = \"./both_eyes_together\"\n",
    "dataset = load_dataset('imagefolder', data_dir=path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c2bb8239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb580b2637946a59cb913ea2244442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/1184 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[135]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataset.save_to_disk(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./datasets/both_eyes_together\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\dataset_dict.py:1299\u001b[39m, in \u001b[36mDatasetDict.save_to_disk\u001b[39m\u001b[34m(self, dataset_dict_path, max_shard_size, num_shards, num_proc, storage_options)\u001b[39m\n\u001b[32m   1297\u001b[39m     json.dump({\u001b[33m\"\u001b[39m\u001b[33msplits\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m)}, f)\n\u001b[32m   1298\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m-> \u001b[39m\u001b[32m1299\u001b[39m     dataset.save_to_disk(\n\u001b[32m   1300\u001b[39m         posixpath.join(dataset_dict_path, k),\n\u001b[32m   1301\u001b[39m         num_shards=num_shards.get(k),\n\u001b[32m   1302\u001b[39m         max_shard_size=max_shard_size,\n\u001b[32m   1303\u001b[39m         num_proc=num_proc,\n\u001b[32m   1304\u001b[39m         storage_options=storage_options,\n\u001b[32m   1305\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\arrow_dataset.py:1562\u001b[39m, in \u001b[36mDataset.save_to_disk\u001b[39m\u001b[34m(self, dataset_path, max_shard_size, num_shards, num_proc, storage_options)\u001b[39m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m   1561\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m kwargs \u001b[38;5;129;01min\u001b[39;00m kwargs_per_job:\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m job_id, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset._save_to_disk_single(**kwargs):\n\u001b[32m   1563\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[32m   1564\u001b[39m                 shards_done += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\arrow_dataset.py:1595\u001b[39m, in \u001b[36mDataset._save_to_disk_single\u001b[39m\u001b[34m(job_id, shard, fpath, storage_options)\u001b[39m\n\u001b[32m   1593\u001b[39m _time = time.time()\n\u001b[32m   1594\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pa_table \u001b[38;5;129;01min\u001b[39;00m shard.with_format(\u001b[33m\"\u001b[39m\u001b[33marrow\u001b[39m\u001b[33m\"\u001b[39m).iter(batch_size):\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m     writer.write_table(pa_table)\n\u001b[32m   1596\u001b[39m     num_examples_progress_update += \u001b[38;5;28mlen\u001b[39m(pa_table)\n\u001b[32m   1597\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m time.time() > _time + config.PBAR_REFRESH_TIME_INTERVAL:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\arrow_writer.py:624\u001b[39m, in \u001b[36mArrowWriter.write_table\u001b[39m\u001b[34m(self, pa_table, writer_batch_size)\u001b[39m\n\u001b[32m    622\u001b[39m pa_table = table_cast(pa_table, \u001b[38;5;28mself\u001b[39m._schema)\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embed_local_files:\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m     pa_table = embed_table_storage(pa_table)\n\u001b[32m    625\u001b[39m \u001b[38;5;28mself\u001b[39m._num_bytes += pa_table.nbytes\n\u001b[32m    626\u001b[39m \u001b[38;5;28mself\u001b[39m._num_examples += pa_table.num_rows\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\table.py:2271\u001b[39m, in \u001b[36membed_table_storage\u001b[39m\u001b[34m(table)\u001b[39m\n\u001b[32m   2267\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Features, require_storage_embed\n\u001b[32m   2269\u001b[39m features = Features.from_arrow_schema(table.schema)\n\u001b[32m   2270\u001b[39m arrays = [\n\u001b[32m-> \u001b[39m\u001b[32m2271\u001b[39m     embed_array_storage(table[name], feature) \u001b[38;5;28;01mif\u001b[39;00m require_storage_embed(feature) \u001b[38;5;28;01melse\u001b[39;00m table[name]\n\u001b[32m   2272\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m   2273\u001b[39m ]\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pa.Table.from_arrays(arrays, schema=features.arrow_schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\table.py:1795\u001b[39m, in \u001b[36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[39m\u001b[34m(array, *args, **kwargs)\u001b[39m\n\u001b[32m   1793\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(array, *args, **kwargs):\n\u001b[32m   1794\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, pa.ChunkedArray):\n\u001b[32m-> \u001b[39m\u001b[32m1795\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pa.chunked_array([func(chunk, *args, **kwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array.chunks])\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(array, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\table.py:2140\u001b[39m, in \u001b[36membed_array_storage\u001b[39m\u001b[34m(array, feature)\u001b[39m\n\u001b[32m   2138\u001b[39m     array = array.storage\n\u001b[32m   2139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(feature, \u001b[33m\"\u001b[39m\u001b[33membed_storage\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m feature.embed_storage(array)\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pa.types.is_struct(array.type):\n\u001b[32m   2142\u001b[39m     \u001b[38;5;66;03m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n\u001b[32m   2143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature.feature, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\features\\image.py:274\u001b[39m, in \u001b[36mImage.embed_storage\u001b[39m\u001b[34m(self, storage)\u001b[39m\n\u001b[32m    269\u001b[39m         bytes_ = f.read()\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bytes_\n\u001b[32m    272\u001b[39m bytes_array = pa.array(\n\u001b[32m    273\u001b[39m     [\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         (path_to_bytes(x[\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m x[\u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    275\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m storage.to_pylist()\n\u001b[32m    276\u001b[39m     ],\n\u001b[32m    277\u001b[39m     \u001b[38;5;28mtype\u001b[39m=pa.binary(),\n\u001b[32m    278\u001b[39m )\n\u001b[32m    279\u001b[39m path_array = pa.array(\n\u001b[32m    280\u001b[39m     [os.path.basename(path) \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m storage.field(\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m).to_pylist()],\n\u001b[32m    281\u001b[39m     \u001b[38;5;28mtype\u001b[39m=pa.string(),\n\u001b[32m    282\u001b[39m )\n\u001b[32m    283\u001b[39m storage = pa.StructArray.from_arrays([bytes_array, path_array], [\u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m], mask=bytes_array.is_null())\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\utils\\py_utils.py:309\u001b[39m, in \u001b[36mno_op_if_value_is_null.<locals>.wrapper\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(value):\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(value) \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\features\\image.py:268\u001b[39m, in \u001b[36mImage.embed_storage.<locals>.path_to_bytes\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    266\u001b[39m \u001b[38;5;129m@no_op_if_value_is_null\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpath_to_bytes\u001b[39m(path):\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m xopen(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    269\u001b[39m         bytes_ = f.read()\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bytes_\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\conda\\envs\\biometric\\Lib\\site-packages\\datasets\\utils\\file_utils.py:943\u001b[39m, in \u001b[36mxopen\u001b[39m\u001b[34m(file, mode, download_config, *args, **kwargs)\u001b[39m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_path(main_hop):\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# ignore fsspec-specific kwargs\u001b[39;00m\n\u001b[32m    942\u001b[39m     kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mblock_size\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(main_hop, mode, *args, **kwargs)\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# add headers and cookies for authentication on the HF Hub and for Google Drive\u001b[39;00m\n\u001b[32m    945\u001b[39m file, storage_options = _prepare_path_and_storage_options(file_str, download_config=download_config)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dataset.save_to_disk(f\"./datasets/both_eyes_together\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
