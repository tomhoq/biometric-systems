Output:  /zhome/77/9/213690/biometrics/out/VIT-21k/Run_0-2
Epochs:  3
Learning rate:  0.0001
Dataset:  right_eyes_only
Batch size:  16
Labels of Dataset: ['female', 'male']
Loaded accuracy
ViTImageProcessor {
  "do_convert_rgb": null,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "image_mean": [
    0.5,
    0.5,
    0.5
  ],
  "image_processor_type": "ViTImageProcessor",
  "image_std": [
    0.5,
    0.5,
    0.5
  ],
  "resample": 2,
  "rescale_factor": 0.00392156862745098,
  "size": {
    "height": 224,
    "width": 224
  }
}

ViTForImageClassification(
  (vit): ViTModel(
    (embeddings): ViTEmbeddings(
      (patch_embeddings): ViTPatchEmbeddings(
        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): ViTEncoder(
      (layer): ModuleList(
        (0-11): 12 x ViTLayer(
          (attention): ViTAttention(
            (attention): ViTSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
            )
            (output): ViTSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (intermediate): ViTIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): ViTOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
          )
          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        )
      )
    )
    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
  )
  (classifier): Linear(in_features=768, out_features=2, bias=True)
)
{'loss': 0.6791, 'grad_norm': 1.0568691492080688, 'learning_rate': 9.6e-05, 'epoch': 0.13}
{'loss': 0.5825, 'grad_norm': 4.037698745727539, 'learning_rate': 9.155555555555557e-05, 'epoch': 0.27}
{'loss': 0.6253, 'grad_norm': 2.485915184020996, 'learning_rate': 8.711111111111112e-05, 'epoch': 0.4}
{'loss': 0.47, 'grad_norm': 4.41461706161499, 'learning_rate': 8.266666666666667e-05, 'epoch': 0.53}
{'loss': 0.4968, 'grad_norm': 2.985714912414551, 'learning_rate': 7.822222222222223e-05, 'epoch': 0.67}
{'eval_loss': 0.3774329125881195, 'eval_accuracy': 0.8433333333333334, 'eval_runtime': 3.7576, 'eval_samples_per_second': 79.838, 'eval_steps_per_second': 10.113, 'epoch': 0.67}
{'loss': 0.3999, 'grad_norm': 3.6384005546569824, 'learning_rate': 7.377777777777778e-05, 'epoch': 0.8}
{'loss': 0.3678, 'grad_norm': 2.362454891204834, 'learning_rate': 6.933333333333334e-05, 'epoch': 0.93}
{'loss': 0.3469, 'grad_norm': 5.497093677520752, 'learning_rate': 6.488888888888889e-05, 'epoch': 1.07}
{'loss': 0.4322, 'grad_norm': 8.323468208312988, 'learning_rate': 6.044444444444445e-05, 'epoch': 1.2}
{'loss': 0.3332, 'grad_norm': 3.114201068878174, 'learning_rate': 5.6000000000000006e-05, 'epoch': 1.33}
{'eval_loss': 0.37305784225463867, 'eval_accuracy': 0.8466666666666667, 'eval_runtime': 3.6978, 'eval_samples_per_second': 81.13, 'eval_steps_per_second': 10.277, 'epoch': 1.33}
{'loss': 0.2456, 'grad_norm': 2.883390426635742, 'learning_rate': 5.1555555555555556e-05, 'epoch': 1.47}
{'loss': 0.2394, 'grad_norm': 1.9152042865753174, 'learning_rate': 4.711111111111111e-05, 'epoch': 1.6}
{'loss': 0.1587, 'grad_norm': 4.806511402130127, 'learning_rate': 4.266666666666667e-05, 'epoch': 1.73}
{'loss': 0.1776, 'grad_norm': 5.460952281951904, 'learning_rate': 3.8222222222222226e-05, 'epoch': 1.87}
{'loss': 0.2605, 'grad_norm': 0.8057795166969299, 'learning_rate': 3.377777777777778e-05, 'epoch': 2.0}
{'eval_loss': 0.2916651964187622, 'eval_accuracy': 0.8866666666666667, 'eval_runtime': 3.7394, 'eval_samples_per_second': 80.227, 'eval_steps_per_second': 10.162, 'epoch': 2.0}
{'loss': 0.1034, 'grad_norm': 0.23163126409053802, 'learning_rate': 2.9333333333333336e-05, 'epoch': 2.13}
{'loss': 0.1281, 'grad_norm': 0.6241541504859924, 'learning_rate': 2.488888888888889e-05, 'epoch': 2.27}
{'loss': 0.0563, 'grad_norm': 0.21575991809368134, 'learning_rate': 2.0444444444444446e-05, 'epoch': 2.4}
{'loss': 0.1341, 'grad_norm': 6.7239789962768555, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.53}
{'loss': 0.0817, 'grad_norm': 0.7362585067749023, 'learning_rate': 1.1555555555555556e-05, 'epoch': 2.67}
{'eval_loss': 0.24317967891693115, 'eval_accuracy': 0.9166666666666666, 'eval_runtime': 3.6926, 'eval_samples_per_second': 81.244, 'eval_steps_per_second': 10.291, 'epoch': 2.67}
{'loss': 0.1697, 'grad_norm': 0.2333030253648758, 'learning_rate': 7.111111111111112e-06, 'epoch': 2.8}
{'loss': 0.0973, 'grad_norm': 1.8914673328399658, 'learning_rate': 2.666666666666667e-06, 'epoch': 2.93}
{'train_runtime': 103.8124, 'train_samples_per_second': 34.678, 'train_steps_per_second': 2.167, 'train_loss': 0.29381763703293273, 'epoch': 3.0}
***** train metrics *****
  epoch                    =         3.0
  total_flos               = 259812141GF
  train_loss               =      0.2938
  train_runtime            =  0:01:43.81
  train_samples_per_second =      34.678
  train_steps_per_second   =       2.167
Labels of Dataset: ['female', 'male']
Classification Metrics
Accuracy     : 0.917
Precision     : 0.912
Recall        : 0.905 (Sensitivity)
Specificity   : 0.926
F1 Score      : 0.908
AUC           : 0.972
EER:          : 0.080
